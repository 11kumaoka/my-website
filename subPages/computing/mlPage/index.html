<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>KumaWiki HTML版</title>
  <style>
    body {
      font-family: "Hiragino Sans", sans-serif;
      line-height: 1.6;
      background-color: #fefefe;
      padding: 2rem;
      color: #333;
    }
    pre {
      background: #222;
      color: #b6ff01;
      padding: 0.1rem;
      padding-left: 0.5rem;
      overflow-x: auto;
    }
    h2{
      padding-left: 0.2rem;
      color: rgb(25, 149, 0);
      background-color: #ffea63;
    }
    h3{
      padding-left: 0.3rem;
      color: #42bc00;
    }
    h4 {
      padding-left: 0.4rem;
      color: #005c11;
    }
    img {
      max-width: 100%;
      height: auto;
    }
    summary {
      cursor: pointer;
      font-weight: bold;
    }
  </style>
</head>
<body>


<!-- <details><summary>
  mode="div"
  showlink="Table of Contents..."
  hidelink="Hide"
  showimgleft="%ICONURLPATH{toggleopen-small</summary>"
  hideimgleft="%ICONURLPATH{toggleclose-small</summary>"
 </summary> -->

 <!-- パンくずリスト -->
<nav class="breadcrumb">
  <a href="/my-website/index.html">ホーム</a> &gt;
  <span>EIC Physics</span>
</nav>




<h2>ベイズ統計</h2>
<p>ベイズ統計は、事前分布と事後分布を用いてデータ解析を行う手法です。以下に、ベイズ統計の基本的な概念と用語を示します。</p>
<details>
  <summary>ベイズ統計の基本概念</summary>
  <ul>
    <li><strong>事前分布 (Prior Distribution)</strong>: データを観測する前に、パラメータに対して持っている信念や知識を表す分布。</li>
    <li><strong>尤度 (Likelihood)</strong>: 観測データが与えられたとき、パラメータが特定の値をとる確率。</li>
    <li><strong>事後分布 (Posterior Distribution)</strong>: 観測データを考慮した後のパラメータの分布。ベイズの定理を用いて計算される。</li>
    <li><strong>ベイズの定理 (Bayes' Theorem)</strong>: 事前分布と尤度から事後分布を求めるための公式。</li>
  </ul>
</details>
<h3>ベイズの定理</h3>
<p>ベイズの定理は、事前分布と尤度を用いて事後分布を求めるための公式です。以下に、ベイズの定理の数式を示します。</p>
<pre>
P(θ | D) = \frac{P(D | θ) P(θ)}{P(D)}
</pre>
<p>ここで、</p>
<ul>
  <li><strong>P(θ | D)</strong>: 事後分布（パラメータθがデータDを与えたときの確率）</li>
  <li><strong>P(D | θ)</strong>: 尤度（データDがパラメータθのもとで観測される確率）</li>
  <li><strong>P(θ)</strong>: 事前分布（パラメータθに対する事前の信念）</li>
  <li><strong>P(D)</strong>: 周辺尤度（データDが観測される全体の確率）</li>
</ul>
<h3>ベイズ統計の利点</h3>
<p>ベイズ統計の利点は以下の通りです。</p>
<ul>
  <li>事前知識を組み込むことができる。</li>
  <li>パラメータの不確実性を定量化できる。</li>
  <li>データが少ない場合でも、事前分布を利用して推定が可能。</li>
  <li>モデルの比較や選択において、ベイズ因子を用いることができる。</li>
  <li>複雑なモデルや非線形な関係を扱うことができる。</li>
</ul>
<p>すごく参考になったサイト:</p>
<ul>
  <li><a href="https://www.slideshare.net/slideshow/ss-50740386/50740386">学部生向けベイズ統計イントロ(公開版)</a></li>
</ul>


<h2>Jet exam</h2>
<a href="https://indico.nikhef.nl/event/1122/contribution/6/material/slides/0.pdf">https://indico.nikhef.nl/event/1122/contribution/6/material/slides/0.pdf</a>
<a href="https://indico.bnl.gov/event/11322/contributions/49369/attachments/35102/57091/HBossi_RHIC_AGS_UsersMeeting_2021.pdf">https://indico.bnl.gov/event/11322/contributions/49369/attachments/35102/57091/HBossi_RHIC_AGS_UsersMeeting_2021.pdf</a>

<h2>RAA ALICE 2018 AN</h2>
<a href="https://alice-notes.web.cern.ch/node/1005">https://alice-notes.web.cern.ch/node/1005</a>

<h2>CERN ML framework</h2>
<p>refLink</p>
<p>scikit-learn</p>
<a href="https://github.com/fcatalan92/starterkitML19">https://github.com/fcatalan92/starterkitML19</a>
<h2>OpenCV (This is suitable for machine learning of image analysis)</h2>
<a href="http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/index.html">http://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/index.html</a>
<h2>TMVA (It is ROOT base)</h2>
<a href="https://www.icepp.s.u-tokyo.ac.jp/atlas/tutorials/2016/TMVA_2016-12-28.pdf">https://www.icepp.s.u-tokyo.ac.jp/atlas/tutorials/2016/TMVA_2016-12-28.pdf</a>
<a href="http://tmva.sourceforge.net/">http://tmva.sourceforge.net/</a>
<a href="https://twiki.cern.ch/twiki/bin/view/TMVA/WebHome">https://twiki.cern.ch/twiki/bin/view/TMVA/WebHome</a>
<h2>Workshop</h2>
<a href="https://indico.cern.ch/event/668017/">https://indico.cern.ch/event/668017/</a>
<a href="https://indico.cern.ch/event/852553/contributions/">https://indico.cern.ch/event/852553/contributions/</a>
